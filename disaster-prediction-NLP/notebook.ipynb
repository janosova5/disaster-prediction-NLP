{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when installing the libraries after cloning the repository, use this command: pip install -r requirements.txt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import setuptools.dist\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Embedding, SimpleRNN, LSTM\n",
    "from keras.utils import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unidecode\n",
    "\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    # Odstránenie URL\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    # Odstránenie hashtagov\n",
    "    text = re.sub(r'#\\w+', '', text)\n",
    "    # Odstránenie viacnásobných otáznikov a výkričníkov\n",
    "    text = re.sub(r'(\\?{2,}|\\!{2,})', '', text)\n",
    "    # Odstránenie špeciálnych znakov (ponechanie len alfanumerických znakov a medzier)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Normalizácia textu - odstránenie diakritiky\n",
    "    text = unidecode.unidecode(text)\n",
    "    # Previesť text na malé písmená\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "def remove_numbers(text):\n",
    "    return re.sub(r'\\d+', '', text)\n",
    "\n",
    "def clean_data(df):\n",
    "  \n",
    "    clean_df = df.copy()\n",
    "    clean_df.drop(columns=['location'], inplace=True)\n",
    "    clean_df['keyword'].fillna('unknown', inplace=True)\n",
    "    clean_df['keyword'] = clean_df['keyword'].apply(clean_text)\n",
    "    clean_df['keyword'] = clean_df['keyword'].apply(remove_numbers)\n",
    "    clean_df['text'] = clean_df['text'].apply(clean_text)\n",
    "\n",
    "    return clean_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>our deeds are the reason of this  may allah fo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>unknown</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>unknown</td>\n",
       "      <td>all residents asked to shelter in place are be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>unknown</td>\n",
       "      <td>13000 people receive  evacuation orders in cal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>unknown</td>\n",
       "      <td>just got sent this photo from ruby  as smoke f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>unknown</td>\n",
       "      <td>update  california hwy 20 closed in both dire...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>unknown</td>\n",
       "      <td>heavy rain causes flash flooding of streets ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13</td>\n",
       "      <td>unknown</td>\n",
       "      <td>im on top of the hill and i can see a fire in ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>unknown</td>\n",
       "      <td>theres an emergency evacuation happening now i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15</td>\n",
       "      <td>unknown</td>\n",
       "      <td>im afraid that the tornado is coming to our area</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16</td>\n",
       "      <td>unknown</td>\n",
       "      <td>three people died from the heat wave so far</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>17</td>\n",
       "      <td>unknown</td>\n",
       "      <td>haha south tampa is getting flooded hah wait a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>18</td>\n",
       "      <td>unknown</td>\n",
       "      <td>18 or 19 days ive lost count</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>19</td>\n",
       "      <td>unknown</td>\n",
       "      <td>in bago myanmar  arrived bago</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20</td>\n",
       "      <td>unknown</td>\n",
       "      <td>damage to school bus on 80 in multi car crash</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>23</td>\n",
       "      <td>unknown</td>\n",
       "      <td>whats up man</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>24</td>\n",
       "      <td>unknown</td>\n",
       "      <td>i love fruits</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>25</td>\n",
       "      <td>unknown</td>\n",
       "      <td>summer is lovely</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>26</td>\n",
       "      <td>unknown</td>\n",
       "      <td>my car is so fast</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>28</td>\n",
       "      <td>unknown</td>\n",
       "      <td>what a goooooooaaaaaal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  keyword                                               text  target\n",
       "0    1  unknown  our deeds are the reason of this  may allah fo...       1\n",
       "1    4  unknown              forest fire near la ronge sask canada       1\n",
       "2    5  unknown  all residents asked to shelter in place are be...       1\n",
       "3    6  unknown  13000 people receive  evacuation orders in cal...       1\n",
       "4    7  unknown  just got sent this photo from ruby  as smoke f...       1\n",
       "5    8  unknown   update  california hwy 20 closed in both dire...       1\n",
       "6   10  unknown    heavy rain causes flash flooding of streets ...       1\n",
       "7   13  unknown  im on top of the hill and i can see a fire in ...       1\n",
       "8   14  unknown  theres an emergency evacuation happening now i...       1\n",
       "9   15  unknown   im afraid that the tornado is coming to our area       1\n",
       "10  16  unknown        three people died from the heat wave so far       1\n",
       "11  17  unknown  haha south tampa is getting flooded hah wait a...       1\n",
       "12  18  unknown                      18 or 19 days ive lost count        1\n",
       "13  19  unknown                      in bago myanmar  arrived bago       1\n",
       "14  20  unknown    damage to school bus on 80 in multi car crash         1\n",
       "15  23  unknown                                       whats up man       0\n",
       "16  24  unknown                                      i love fruits       0\n",
       "17  25  unknown                                   summer is lovely       0\n",
       "18  26  unknown                                  my car is so fast       0\n",
       "19  28  unknown                             what a goooooooaaaaaal       0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_data = clean_data(train_data)\n",
    "\n",
    "new_train_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/lenocka/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "def add_hashtags_column(df):\n",
    "    new_df = df.copy()\n",
    "    # Extract words that start with '#' and remove the '#' symbol and remove also special characters and numbers\n",
    "    new_df['hashtags'] = new_df['text'].apply(\n",
    "        lambda x: [re.sub(r'[^a-zA-Z]', '', re.sub(r'^#+', '', word)) for word in x.split() if word.startswith('#')]\n",
    "    )\n",
    "    return new_df\n",
    "def get_sentiment(text):\n",
    "    # Initialize VADER sentiment intensity analyzer\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    sentiment_score = sia.polarity_scores(text)\n",
    "    if sentiment_score['compound'] >= 0.05:\n",
    "        return 'Positive'\n",
    "    elif sentiment_score['compound'] <= -0.05:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_clean_data = add_hashtags_column(train_data)\n",
    "new_clean_data = clean_data(new_clean_data)\n",
    "new_clean_data['sentiment'] = new_clean_data['text'].apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>our deeds are the reason of this  may allah fo...</td>\n",
       "      <td>1</td>\n",
       "      <td>[earthquake]</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>unknown</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>unknown</td>\n",
       "      <td>all residents asked to shelter in place are be...</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>unknown</td>\n",
       "      <td>13000 people receive  evacuation orders in cal...</td>\n",
       "      <td>1</td>\n",
       "      <td>[wildfires]</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>unknown</td>\n",
       "      <td>just got sent this photo from ruby  as smoke f...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Alaska, wildfires]</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  keyword                                               text  target  \\\n",
       "0   1  unknown  our deeds are the reason of this  may allah fo...       1   \n",
       "1   4  unknown              forest fire near la ronge sask canada       1   \n",
       "2   5  unknown  all residents asked to shelter in place are be...       1   \n",
       "3   6  unknown  13000 people receive  evacuation orders in cal...       1   \n",
       "4   7  unknown  just got sent this photo from ruby  as smoke f...       1   \n",
       "\n",
       "              hashtags sentiment  \n",
       "0         [earthquake]  Positive  \n",
       "1                   []  Negative  \n",
       "2                   []  Negative  \n",
       "3          [wildfires]   Neutral  \n",
       "4  [Alaska, wildfires]   Neutral  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_clean_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "# Load SpaCy model\n",
    "nlp = spacy.load('en_core_web_sm')  # Or 'en_core_web_lg' for larger vectors\n",
    "\n",
    "def preprocess_and_vec(text):\n",
    "    # Process the text with SpaCy\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Filter out stop words and punctuation, and collect lemmatized tokens\n",
    "    filtered_text = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
    "    \n",
    "    # Check if there are no valid tokens\n",
    "    if not filtered_text:\n",
    "        print('empty', doc)\n",
    "        return None\n",
    "    \n",
    "    # Retrieve vectors for each token in filtered_text\n",
    "    vectors = [token.vector for token in doc if token.lemma_ in filtered_text]\n",
    "    \n",
    "    if vectors:\n",
    "        # Calculate the mean vector of the words\n",
    "        mean_vector = np.mean(vectors, axis=0)\n",
    "        return mean_vector\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_clean_data['vector'] = new_clean_data['text'].apply(preprocess_and_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def label_encoding(df):\n",
    "    # Initialize the LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "    new_df = df.copy()\n",
    "\n",
    "    # Fit and transform the 'sentiment' column\n",
    "    new_df['sentiment'] = label_encoder.fit_transform(new_df['sentiment'])\n",
    "    new_df['keyword'] = label_encoder.fit_transform(new_df['keyword'])\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_clean_data = label_encoding(new_clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = new_clean_data[['vector', 'keyword', 'sentiment']]\n",
    "X = new_clean_data['vector']\n",
    "y = new_clean_data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=0.2, # 20% samples will go to test dataset\n",
    "    random_state=2022,\n",
    "    stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6090"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6090"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.81      0.75       869\n",
      "           1       0.67      0.51      0.58       654\n",
      "\n",
      "    accuracy                           0.68      1523\n",
      "   macro avg       0.68      0.66      0.66      1523\n",
      "weighted avg       0.68      0.68      0.68      1523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_2d = np.stack(X_train)\n",
    "X_test_2d = np.stack(X_test)\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Proceed with model fitting\n",
    "\n",
    "clf.fit(X_train_2d, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_2d)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
